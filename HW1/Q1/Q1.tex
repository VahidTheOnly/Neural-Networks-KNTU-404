\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{xepersian}
\settextfont{Amiri}
\setlatintextfont{Times New Roman}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{geometry}
\geometry{margin=2.5cm}
\usepackage{graphicx}
\usepackage{caption}

\title{تکلیف اول درس شبکه های عصبی}
\author{وحید ملکی \\ شماره دانشجویی: 40313004}
\date{\today}

\begin{document}
	
	\maketitle
	
	\section*{سوال ۱}
	
	به نمودار زیر توجه کنید که تعداد iteration های گرادیان کاهشی تصادفی SGD لازم برای رسیدن به یک مقدار مشخص از تابع زیان را برحسب Batch Size نشان می‌دهد.
	
	\begin{figure}[h]
		\centering
		 \includegraphics[width=0.8\textwidth]{sgd_batchsize_iterations.png}
		\caption{تعداد iteration های گرادیان کاهشی تصادفی SGD لازم برای رسیدن به یک مقدار مشخص از تابع زیان}
		\label{fig:sgd_batchsize}
	\end{figure}
	
	\textbf{الف:} برای batch sizeهای کوچک، هرچه اندازه‌ی batch افزایش می‌یابد، تعداد تکرارهای لازم برای رسیدن به مقدار هدف تابع زیان کاهش می‌یابد. چرا؟
	
	\textbf{ب:} برای batch sizeهای بزرگ، با افزایش اندازه‌ی batch تعداد تکرارها تغییر چندانی نمی‌کند. چرا؟
	
	\subsection*{پاسخ}
	
	با توجه به نمودار ارائه‌شده در شکل \ref{fig:sgd_batchsize} که ارتباط بین اندازه بچ (\lr{Batch Size}) و تعداد تکرارهای (\lr{Iterations}) لازم برای الگوریتم SGD جهت رسیدن به خطای مشخصی را نشان می‌دهد، پاسخ به سوالات به شرح زیر است:
	
	\subsubsection*{الف: کاهش تعداد تکرارها با افزایش اندازه بچ (در اندازه‌های کوچک)}
	
	در اندازه‌های بچ کوچک، با افزایش اندازه بچ، تعداد تکرارهای لازم برای رسیدن به یک مقدار خطای مشخص کاهش می‌یابد. دلیل اصلی این پدیده، \textbf{افزایش دقت تخمین گرادیان} است:
	
	\begin{itemize}
		\item \textbf{نویز در گرادیان:} در الگوریتم SGD، گرادیان در هر مرحله تنها بر اساس یک زیرمجموعه کوچک (بچ) از داده‌ها محاسبه می‌شود. این امر باعث ایجاد نویز در تخمین گرادیان نسبت به گرادیان واقعی (محاسبه‌شده بر کل داده‌ها) می‌گردد.
		
		\item \textbf{اثر اندازه بچ کوچک:} وقتی اندازه بچ بسیار کوچک باشد (مثلاً ۱ یا ۲)، نویز بسیار بالاست. این نویز باعث نوسانات شدید در جهت به‌روزرسانی پارامترها و حرکت پرپیچ‌وخم به سمت نقطه بهینه می‌شود. در نتیجه، الگوریتم مسیر طولانی‌تری را طی کرده و به تکرارهای بیشتری نیاز دارد.
		
		\item \textbf{اثر افزایش اندازه بچ:} با افزایش اندازه بچ، تعداد نمونه‌های دخیل در محاسبه گرادیان افزایش می‌یابد. این امر میانگین‌گیری بهتری انجام داده و تخمین گرادیان را به گرادیان واقعی نزدیک‌تر می‌کند. گرادیان دقیق‌تر منجر به حرکت مستقیم‌تر و پایدارتر به سمت مینیمم تابع زیان شده و در نتیجه \textbf{تعداد تکرارهای لازم کاهش می‌یابد}.
	\end{itemize}
	
	\subsubsection*{ب: عدم تغییر محسوس تعداد تکرارها با افزایش اندازه بچ (در اندازه‌های بزرگ)}
	
	در اندازه‌های بچ بزرگ، با افزایش بیشتر اندازه بچ، تعداد تکرارها تقریباً ثابت می‌ماند. این پدیده که به \textbf{نقطه اشباع (\lr{Saturation Point})} معروف است، به دلایل زیر رخ می‌دهد:
	
	\begin{itemize}
		\item \textbf{بازده نزولی (\lr{Diminishing Returns}):} پس از رسیدن به یک اندازه بچ کافی، گرادیان تخمینی به اندازه‌ای دقیق می‌شود که افزودن نمونه‌های بیشتر، بهبود قابل‌توجهی در دقت آن ایجاد نمی‌کند. اطلاعات اضافی حاصل از نمونه‌های بیشتر، تأثیر ناچیزی بر جهت کلی گرادیان دارد.
		
		\item \textbf{اشباع کیفیت گرادیان:} وقتی اندازه بچ به اندازه کافی بزرگ باشد، گرادیان محاسبه‌شده نماینده بسیار خوبی از گرادیان واقعی است. در این حالت، الگوریتم در هر تکرار نزدیک به بهترین جهت ممکن را طی می‌کند و افزایش بیشتر اندازه بچ نمی‌تواند این مسیر را بهینه‌تر کند. بنابراین، \textbf{تعداد گام‌های لازم برای همگرایی ثابت می‌ماند}.
		
		\item \textbf{افزایش هزینه محاسباتی:} هرچند تعداد تکرارها تغییر نمی‌کند، اما افزایش اندازه بچ باعث افزایش حجم محاسبات در هر تکرار می‌شود. این امر زمان کل آموزش را افزایش می‌دهد، بدون بهبود سرعت همگرایی (از نظر تعداد تکرار). از این رو، انتخاب اندازه بچ مناسب یک \textbf{مصالحه بین دقت گرادیان و کارایی محاسباتی} است.
	\end{itemize}
	
	در نهایت، نمودار نشان می‌دهد که یک اندازه بچ بهینه وجود دارد که تعادل مناسبی بین نویز گرادیان و هزینه محاسباتی برقرار می‌کند.
	
\end{document}